{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Calibration example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "import numpy.linalg as linalg\n",
    "#For plots\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#ucl\n",
    "from scipy.stats import f as fisher\n",
    "\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de la matriz de calibración son:  (300, 112)\n"
     ]
    }
   ],
   "source": [
    "#Generación e matriz aleatoria arbitraria\n",
    "nobs=300\n",
    "nvar=112\n",
    "calibration_matrix=np.random.random((nobs,nvar)) #matriz de 300x112\n",
    "#comprobar\n",
    "print \"Las dimensiones de la matriz de calibración son: \", calibration_matrix.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información adicional para el cálculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuraciones\n",
    "tstsDateFormat='%Y%m%d%H%M'\n",
    "model_backup_path = \"data/calibration/\"\n",
    "datetime.strftime(datetime.now(),tstsDateFormat)\n",
    "\n",
    "#información del yaml de configuración principal\n",
    "prep=2\n",
    "lv=2\n",
    "phase=1\n",
    "x=calibration_matrix\n",
    "\n",
    "flag=0 #bandera utilizada para la correcta concatenación con las matrices dataXX\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de la matriz calibración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average:  [[0.52703187 0.49496778 0.51868074 0.45196426 0.49832919 0.50141388\n",
      "  0.50216666 0.51950448 0.48542888 0.52397353 0.49687927 0.50960788\n",
      "  0.47280477 0.48468202 0.51562946 0.52034764 0.51151902 0.49007326\n",
      "  0.48373926 0.49812368 0.48528434 0.44899192 0.50750997 0.48309122\n",
      "  0.49444448 0.51770407 0.49624327 0.51751457 0.49267093 0.48518288\n",
      "  0.5029653  0.48375409 0.49560583 0.48950551 0.50772342 0.52979699\n",
      "  0.4849784  0.49987062 0.50095729 0.48667154 0.51499265 0.48581532\n",
      "  0.5030267  0.50312893 0.54882531 0.52322012 0.48891966 0.4945721\n",
      "  0.49814305 0.50362456 0.48497878 0.49005466 0.51462103 0.50445466\n",
      "  0.5170788  0.50299164 0.50865398 0.50220042 0.4976685  0.48220148\n",
      "  0.4925944  0.48491542 0.51717139 0.52465388 0.50312872 0.48989029\n",
      "  0.53077866 0.52444244 0.49304748 0.50716789 0.52860986 0.46659265\n",
      "  0.49654221 0.49479887 0.47573364 0.49192882 0.51139373 0.51697499\n",
      "  0.5010183  0.51462418 0.48095177 0.48905678 0.51166515 0.47572711\n",
      "  0.48633143 0.50536249 0.50103878 0.5100321  0.52223337 0.50286289\n",
      "  0.49012808 0.49640911 0.48821545 0.47486757 0.48592216 0.5211686\n",
      "  0.52820282 0.51695243 0.52770563 0.49618694 0.52870238 0.46475427\n",
      "  0.4922145  0.50391731 0.50018452 0.51417918 0.51031053 0.51496159\n",
      "  0.52597501 0.50289415 0.49589259 0.48303341]]\n",
      "('Las dimensiones de average: ', (1, 112), ' Se busca el valor medio de csda')\n",
      "scale:  [[0.28943881 0.29441396 0.29408102 0.28305427 0.29132535 0.29576378\n",
      "  0.29251325 0.28261378 0.28469916 0.29236248 0.28804087 0.27720864\n",
      "  0.28237616 0.2905456  0.2895276  0.29089846 0.29291333 0.28111853\n",
      "  0.2831292  0.297597   0.28632093 0.28900154 0.28990789 0.2990046\n",
      "  0.28537912 0.29851785 0.28697151 0.29149791 0.28235634 0.29326727\n",
      "  0.29338968 0.29359379 0.29437593 0.29579255 0.29528962 0.30157319\n",
      "  0.31517181 0.28846306 0.29555651 0.29575632 0.2848095  0.29684855\n",
      "  0.29627472 0.28454105 0.27879279 0.28457632 0.30611836 0.29611157\n",
      "  0.28865102 0.2870902  0.28132148 0.28916137 0.28720868 0.28490094\n",
      "  0.29994337 0.29680812 0.28581627 0.27766531 0.28345006 0.27907129\n",
      "  0.289379   0.29054986 0.28963293 0.29192468 0.29225815 0.30244087\n",
      "  0.2940317  0.28246543 0.29715635 0.28487968 0.29673792 0.29696822\n",
      "  0.29158654 0.29518532 0.2941024  0.26971562 0.2902445  0.29301265\n",
      "  0.28926624 0.28305324 0.29280918 0.28001271 0.28145911 0.28528394\n",
      "  0.30538482 0.29422071 0.28051574 0.29075456 0.28349706 0.28735625\n",
      "  0.28877163 0.29144663 0.27388474 0.28294725 0.30362601 0.28149059\n",
      "  0.27609927 0.28855609 0.29474737 0.2948683  0.27947188 0.29148596\n",
      "  0.28304021 0.28957059 0.29221771 0.2932862  0.29471594 0.30114115\n",
      "  0.30883503 0.29530929 0.28270733 0.29281653]]\n",
      "Las dimensiones de scale son:  (1, 112) Se busca la desviación de cada columna para centrarla en 1\n",
      "xcs:  [[-1.59507207 -0.22232919  0.38510096 ... -0.57234977  1.0263211\n",
      "  -1.21992801]\n",
      " [-0.98887558 -0.71835807 -0.80924406 ... -0.21420909  0.58170647\n",
      "  -1.27464978]\n",
      " [-1.01707324  0.86739162  0.50258993 ...  0.08045121  1.21539231\n",
      "   1.14916099]\n",
      " ...\n",
      " [-1.64702049  0.32702814  0.99809357 ...  0.55016622  1.74659367\n",
      "  -1.01817474]\n",
      " [-0.01914676 -1.21905612  1.31856257 ...  0.29141086 -0.76062795\n",
      "  -1.30520252]\n",
      " [ 1.07951427 -1.40563509 -0.57331113 ...  1.63468283  0.89736954\n",
      "   0.60262256]]\n",
      "Las dimensiones de xcs:  (300, 112)\n",
      "xcs es la matriz normalizada, con media 0 y desviación 1, paso necesario para aplicar PCA\n"
     ]
    }
   ],
   "source": [
    "#preprocesamiento -->method_name = \"preprocess_2D()\" La variables weight de momento en estos ejemplos no la tendremos en cuenta\n",
    "def preproccess(x):\n",
    "    nanM = np.isnan(x)\n",
    "    anM = 1 - nanM\n",
    "\n",
    "    average = np.nanmean(x,axis=0)# array of M elements\n",
    "    average = average.reshape((1,average.shape[0]))# Matrix of 1xM elements\n",
    "    scale = np.nanstd(x,axis=0,ddof=1)\n",
    "\n",
    "    #TODO: to ask Pepe what is this :(\n",
    "    ind = np.nonzero(scale == 0)# # of zeroes in scale\n",
    "    dem = 2.0*np.sum(anM[:,ind],axis=0) - 1\n",
    "    scale[ind] = np.sqrt(np.ones((1,np.array(ind).size)) / dem)\n",
    "\n",
    "    scale = scale.reshape((1,scale.shape[0]))# Matrix of 1xM elements\n",
    "    xcs = x - np.dot(np.ones((x.shape[0],1)),average)\n",
    "    xcs = xcs / np.dot(np.ones((x.shape[0],1)),scale)\n",
    "\n",
    "    print \"average: \", average\n",
    "    print (\"Las dimensiones de average: \", average.shape, \" Se busca el valor medio de csda\")#112x1, es decir, una media por cada columna\n",
    "\n",
    "    print \"scale: \", scale\n",
    "    print \"Las dimensiones de scale son: \", scale.shape, \"Se busca la desviación de cada columna para centrarla en 1\"\n",
    "\n",
    "    #xcs tiene las dimensiones de la matriz original 300x112\n",
    "    print \"xcs: \",xcs\n",
    "    print \"Las dimensiones de xcs: \", xcs.shape\n",
    "    print \"xcs es la matriz normalizada, con media 0 y desviación 1, paso necesario para aplicar PCA\"\n",
    "    \n",
    "    return xcs,average,scale;\n",
    "    \n",
    "xcs,average,scale=preproccess(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de u: (300, 300)\n",
      "Las dimensiones de s: (300, 112)\n",
      "Las dimensiones de v: (112, 112)\n",
      "La dimensiones de t son : (300, 112)\n",
      "Las dimensiones de p son: (112, 112)\n",
      "Las dimensiones de scoresMatrix son: (300, 2)\n",
      "Las dimensiones de loadingsMatrix son: (112, 2)\n",
      "Las dimensiones de model son: (300, 112)\n",
      "Las dimensiones de residualsMatrix son: (300, 112)\n",
      "Las dimensiones de eigengvaluesMatrix son: (300, 112)\n"
     ]
    }
   ],
   "source": [
    "#PCA; La llamada de la funcion def runPCA(self, method='svd', **kwargs):\n",
    "#El ejemplo lo describo con el método svd que es el usado por defecto\n",
    "# Run SVD from the data matrix\n",
    "data=xcs\n",
    "pcs=lv\n",
    "\n",
    "def pca(data, pcs,method='svd', **kwargs):\n",
    "    if method == 'svd':\n",
    "        u, s, v = linalg.svd(data)\n",
    "\n",
    "        # Transform S from array to matrix with the corresponding dimensions\n",
    "        # in U and V\n",
    "        #Este punto no he conseguido obtener una comprensión profunda mas alla de lo que menciona\n",
    "        sdiag = np.diag(s)\n",
    "        s = np.zeros((u.shape[1], v.shape[0]))\n",
    "        s[:sdiag.shape[0], :sdiag.shape[1]] = sdiag\n",
    "\n",
    "        print \"Las dimensiones de u: %s\" % str(u.shape)\n",
    "\n",
    "        print \"Las dimensiones de s: %s\" % str(s.shape)\n",
    "\n",
    "        print \"Las dimensiones de v: %s\" % str(v.shape)\n",
    "\n",
    "        t = np.dot(u, s)   #  ->u: Matriz de similaridad de fila-clase       \n",
    "        p = v.T #            ->v: Matriz de similaridad de columna-clase\n",
    "\n",
    "    elif method == 'eig':\n",
    "        ################EWMA##############\n",
    "        if 'xxcrossdata' not in kwargs:\n",
    "            # Computing cross-product\n",
    "            XX = np.dot(data.T,data)\n",
    "        else:\n",
    "            XX = kwargs['xxcrossdata']     \n",
    "        \n",
    "        # s, eigenvalues\n",
    "        # p, eigenvectors\n",
    "        s,p = linalg.eig(XX)\n",
    "        \n",
    "    \n",
    "        # Sort the eigenvectors their corresponding eigenvalue\n",
    "        ind = np.argsort(s)[::-1]# get the indexes in descending order\n",
    "        p = p[:,ind]# get the complete P matrix\n",
    "        # get the complete score matrix\n",
    "        t = np.dot(data, p)\n",
    "    \n",
    "    \n",
    "    scoresMatrix = t[:, :pcs]  # (Las dos pc's)\n",
    "    loadingsMatrix = p[:, :pcs] #M\n",
    "    model = np.dot(scoresMatrix, loadingsMatrix.T) #Matriz de 300x112\n",
    "    residualsMatrix = data - model #\n",
    "    eigengvaluesMatrix = s #\n",
    "\n",
    "    print \"La dimensiones de t son : %s\" % str(t.shape)\n",
    "    print \"Las dimensiones de p son: %s\" % str(p.shape)\n",
    "    print \"Las dimensiones de scoresMatrix son: %s\" % str(scoresMatrix.shape)\n",
    "    print \"Las dimensiones de loadingsMatrix son: %s\" % str(loadingsMatrix.shape)\n",
    "    print \"Las dimensiones de model son: %s\" % str(model.shape)\n",
    "    print \"Las dimensiones de residualsMatrix son: %s\" % str(residualsMatrix.shape)\n",
    "    print \"Las dimensiones de eigengvaluesMatrix son: %s\" % str(eigengvaluesMatrix.shape)\n",
    "    \n",
    "    return scoresMatrix,loadingsMatrix,model,residualsMatrix,eigengvaluesMatrix\n",
    "\n",
    "scoresMatrix,loadingsMatrix,model,residualsMatrix,eigengvaluesMatrix=pca(data, pcs)\n",
    "#scoresMatrix,loadingsMatrix,model,residualsMatrix,eigengvaluesMatrix=pca(data, pcs,method=\"eig\")\n",
    "\n",
    "#type(data)#numpy.ndarray\n",
    "#data.shape#20, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u, s, v = linalg.svd(data)\n",
    "s.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos los UCL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definido en model.py\n",
    "alpha = 0.01\n",
    "\n",
    "\n",
    "####Para el calculo de UCLD\n",
    "phase=2\n",
    "mspc=lv\n",
    "npc=data.shape[0] #nº observaciones (300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCL-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de UCLD:  9.416825881055232\n"
     ]
    }
   ],
   "source": [
    "####Para el calculo de UCLD\n",
    "phase=2\n",
    "npc=lv\n",
    "nob=data.shape[0]#nº observaciones (300)\n",
    "p_value=alpha #El p_value vale 0.01 muy significativo. A más pequeño más significativo. Basicamente busca le decimos a q que busque anomalías en el p-value dado\n",
    "\n",
    "def calcularUCLD(nobs,p_value,nob,npc):        \n",
    "    if phase == 2:\n",
    "       lim = (npc*(nob*nob-1.0)/(nob*(nob-npc)))*fisher.ppf(1-p_value,npc,nob-npc)\n",
    "    else:\n",
    "       lim = (nob-1.0)**2/nob*beta.ppf(1-p_value,npc/2.0,(nob-npc-1)/2.0)\n",
    "\n",
    "\n",
    "    # Check is the limit is and ndarray of [1x1] dimensions and get the float value\n",
    "    if isinstance(lim, np.ndarray):\n",
    "       lim = lim[0,0]\n",
    "\n",
    "    # TODO: Sometimes after computations numpy takes UCLq as complex with 0j imaginary part\n",
    "    if isinstance(lim, complex):\n",
    "       logging.warn(\"UCLd has a complex value of %s. Getting just the real part.\",lim)\n",
    "       lim = lim.real\n",
    "\n",
    "    UCLD=lim #Valor de ejemplo 9.416825881055232\n",
    "\n",
    "    print \"El valor de UCLD: \",  UCLD\n",
    "    return UCLD\n",
    "\n",
    "UCLD=calcularUCLD(nobs,p_value,nob,npc)   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCL-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de UCLQ:  150.6476374718253\n"
     ]
    }
   ],
   "source": [
    "#definido en model.py\n",
    "#alpha = 0.01\n",
    "\n",
    "####Para el calculo de UCLQ\n",
    "res=residualsMatrix\n",
    "p_value=alpha #El p_value vale 0.01 muy significativo. A más pequeño más significativo. Basicamente busca le decimos a q que busque anomalías en el p-value dado\n",
    "# Rows of E matrix\n",
    "N = res.shape[0] #300 observaciones\n",
    "\n",
    "def calcularUCLQ(res,p_value,N):\n",
    "    # rank of E\n",
    "    pcs_left = np.linalg.matrix_rank(res);#rango 110, este valor variará según la matriz utilizada\n",
    "\n",
    "    #\n",
    "    lambda_eig = np.linalg.eigvals((1.0/(N-1))*np.dot(res.T,res)) #Array de 112 valores, \n",
    "    # Get the DESC order according to the ABS value of eigenvalues\n",
    "    lambda_eig = lambda_eig[np.abs(lambda_eig).argsort()[::-1]]        \n",
    "\n",
    "    theta1 = np.sum(lambda_eig[:pcs_left])\n",
    "    theta2 = np.sum(lambda_eig[:pcs_left]**2)\n",
    "    theta3 = np.sum(lambda_eig[:pcs_left]**3)\n",
    "\n",
    "    h0 = 1-((2*theta1*theta3)/(3*theta2**2))\n",
    "\n",
    "    z = norm.ppf(1-p_value)\n",
    "\n",
    "    UCLq = theta1*((z*np.sqrt(2*theta2*(h0**2))/theta1) + 1 + (theta2*h0*(h0-1)/(theta1**2)))**(1/h0)\n",
    "    #Comprobaciones para evitar errorewres\n",
    "    # Check is the limit is and ndarray of [1x1] dimensions and get the float value\n",
    "    if isinstance(UCLq, np.ndarray):\n",
    "       UCLq = UCLq[0,0]\n",
    "\n",
    "    # TODO: Sometimes after computations numpy takes UCLq as complex with 0j imaginary part\n",
    "    if isinstance(UCLq, complex):\n",
    "        #logging.warn(\"UCLq has a complex value of %s. Getting just the real part.\",UCLq)\n",
    "        UCLq = UCLq.real\n",
    "\n",
    "    UCLQ=UCLq #valor de ejemplo 150.99231878043952\n",
    "\n",
    "    print \"El valor de UCLQ: \", UCLQ\n",
    "    return UCLQ\n",
    "    \n",
    "UCLQ=calcularUCLQ(res,p_value,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de los estadísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[125.44435756]]\n"
     ]
    }
   ],
   "source": [
    "#Comenzamos con el cálculo de Q-st\n",
    "#Primero obtenemos un arry de 1x112\n",
    "test=np.random.random((1,nvar))\n",
    "testMeanCenterting = test - np.dot(np.ones((test.shape[0],1)),average)\n",
    "testAutoScaled = testMeanCenterting / (np.dot(np.ones((test.shape[0],1)),scale))\n",
    "testcs = testAutoScaled\n",
    "\n",
    "def qst(test,loadingsMatrix):\n",
    "    #La preprocesamos, es una funcion distinta a la usada en la matriz de calibración\n",
    "    #Es decir media 0 y desviación 1 respecto la calibración\n",
    "\n",
    "    #Ahora comenzamos el cálculo del estadístico, ¿Qué necesitamos?\n",
    "    #self._mspc.computeQst(testcs, self._model.get_pca().getLoadings())\n",
    "    #La observación preporcesada y la matriz Loading del PCA\n",
    "\n",
    "    #def computeQst(self,testcs,P):\n",
    "    P=loadingsMatrix\n",
    "    #new scores from testcs and the loadings (Q) of the calibration model\n",
    "    t = np.dot(testcs,P)\n",
    "    # Model residuals from the observations in testcs\n",
    "    e = testcs - np.dot(t,np.transpose(P))\n",
    "    # Computes Q-statistics from the observations in testcs\n",
    "    Qst = np.sum(np.power(e,2),axis=1).reshape(testcs.shape[0],1);\n",
    "    #->Qst = 89.84502164\n",
    "\n",
    "    print Qst\n",
    "    \n",
    "qst(test,loadingsMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6043959210168488\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def dst(testcs,loadingsMatrix,scoresMatrix):\n",
    "    testcs=testcs\n",
    "    P=loadingsMatrix\n",
    "    T=scoresMatrix\n",
    "    #new scores from testcs and the loadings (R) of the calibration model\n",
    "    t = np.dot(testcs,P)        \n",
    "\n",
    "    #inverse of the model calibration scores (T)\n",
    "    #Note: inv() method just allows at least 2D arrays \n",
    "    t_cov = np.cov(T,rowvar=False)\n",
    "\n",
    "    try:\n",
    "        invCT = np.linalg.inv(t_cov)\n",
    "    except LinAlgError:\n",
    "        invCT = 1 / t_cov\n",
    "\n",
    "    #         if all(t_cov.shape):# True the shape tuple is empty\n",
    "    #             # When T has only one variable -> cov(T) computes the variance\n",
    "    #             invCT = 1 / t_cov\n",
    "    #         else:    \n",
    "    #             invCT = np.linalg.inv(t_cov)\n",
    "\n",
    "    dotAux = np.dot(t,invCT)\n",
    "\n",
    "    # Computes D-statistics from the observations in testcs\n",
    "    Dst = np.sum(np.multiply(dotAux,t),axis=1).reshape(testcs.shape[0],1);\n",
    "\n",
    "    # Check is the statistic is and ndarray of [1x1] dimensions and get the float value\n",
    "    if isinstance(Dst, np.ndarray):\n",
    "        Dst = Dst[0,0]\n",
    "\n",
    "    # TODO: Sometimes after computations numpy takes UCLq as complex with 0j imaginary part\n",
    "    if isinstance(Dst, complex):\n",
    "        logging.warn(\"Dst has a complex value of %s. Getting just the real part.\",self._Dst)\n",
    "        Dst = Dst.real\n",
    "\n",
    "    print Dst\n",
    "\n",
    "\n",
    "dst(testcs,loadingsMatrix,scoresMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto tenemos calculado los UCL's correspondientes a una calibración y los estadísticos correspondientes a una observación. Para comprobar si tenermos una anomalía tan sólo debemos ver si ambos estadísticos se encuentran por debajo de sus UCL's respectivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnóstico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El punto ahora es poder obtener el origen de dicha anomalía para ello se aplica el método oMEDA calculando un vector de diagnóstico de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.27321658],\n",
       "       [-0.04141097],\n",
       "       [ 0.18944725],\n",
       "       [ 0.01610739],\n",
       "       [ 0.01555297],\n",
       "       [-0.0115277 ],\n",
       "       [ 0.21456273],\n",
       "       [ 0.07302807],\n",
       "       [ 0.37360124],\n",
       "       [-0.46405789],\n",
       "       [ 0.12823342],\n",
       "       [ 0.3730334 ],\n",
       "       [-0.47117272],\n",
       "       [-0.22687801],\n",
       "       [-0.69059074],\n",
       "       [ 0.5498423 ],\n",
       "       [ 0.13108406],\n",
       "       [-0.20403316],\n",
       "       [-0.00603474],\n",
       "       [ 0.19019914],\n",
       "       [-0.52665953],\n",
       "       [-0.41603937],\n",
       "       [ 0.01741002],\n",
       "       [-0.17495931],\n",
       "       [-0.01354988],\n",
       "       [ 0.55965314],\n",
       "       [ 0.64786009],\n",
       "       [ 0.10395043],\n",
       "       [-0.03357466],\n",
       "       [-0.02558825],\n",
       "       [ 0.26766527],\n",
       "       [ 0.10220575],\n",
       "       [-0.01484748],\n",
       "       [-0.17168579],\n",
       "       [ 0.03043265],\n",
       "       [ 0.1667673 ],\n",
       "       [-0.15348577],\n",
       "       [ 0.09045583],\n",
       "       [-0.17371553],\n",
       "       [-0.19677039],\n",
       "       [ 0.07894877],\n",
       "       [ 0.08706348],\n",
       "       [-0.00196742],\n",
       "       [ 0.14222028],\n",
       "       [ 0.51023676],\n",
       "       [-0.049927  ],\n",
       "       [-0.13200989],\n",
       "       [-0.03857297],\n",
       "       [-0.09494723],\n",
       "       [-0.07814767],\n",
       "       [ 0.12514902],\n",
       "       [ 0.08137266],\n",
       "       [-0.01248092],\n",
       "       [ 0.1680096 ],\n",
       "       [-0.00150682],\n",
       "       [-0.03384717],\n",
       "       [-0.24820445],\n",
       "       [-0.02518004],\n",
       "       [ 0.0730305 ],\n",
       "       [ 0.04575829],\n",
       "       [-0.08705828],\n",
       "       [-0.03758917],\n",
       "       [ 0.09078446],\n",
       "       [ 0.2086193 ],\n",
       "       [-0.05024276],\n",
       "       [-0.0513734 ],\n",
       "       [-0.02570808],\n",
       "       [-0.14657204],\n",
       "       [ 0.05737669],\n",
       "       [ 0.44077455],\n",
       "       [-0.09246746],\n",
       "       [ 0.03135997],\n",
       "       [ 0.20802556],\n",
       "       [-0.1286133 ],\n",
       "       [ 0.76475012],\n",
       "       [ 0.07190919],\n",
       "       [-0.11031689],\n",
       "       [-0.20430178],\n",
       "       [ 0.08046544],\n",
       "       [-0.06729223],\n",
       "       [ 0.00134635],\n",
       "       [ 0.08278712],\n",
       "       [ 0.36492116],\n",
       "       [-0.15147429],\n",
       "       [ 0.01261549],\n",
       "       [-0.23761304],\n",
       "       [ 0.11043201],\n",
       "       [-0.00905234],\n",
       "       [-0.21671785],\n",
       "       [ 0.16221562],\n",
       "       [-0.20649282],\n",
       "       [-0.05610185],\n",
       "       [ 0.02470192],\n",
       "       [ 0.08323459],\n",
       "       [-0.31503252],\n",
       "       [ 0.69434411],\n",
       "       [-0.46123084],\n",
       "       [-0.00561276],\n",
       "       [ 0.13290265],\n",
       "       [ 0.2739296 ],\n",
       "       [ 0.1501375 ],\n",
       "       [-0.02753881],\n",
       "       [ 0.3259391 ],\n",
       "       [ 0.01324729],\n",
       "       [ 0.10174037],\n",
       "       [ 0.02609624],\n",
       "       [ 0.05486736],\n",
       "       [-0.00909402],\n",
       "       [ 0.09092909],\n",
       "       [ 0.1006997 ],\n",
       "       [-0.07914824],\n",
       "       [-0.01745665]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def omeda(test,testcs,loadingsMatrix,scoresMatrix):\n",
    "    # Set up which observations are compared\n",
    "    dummy = np.zeros((1,test.shape[0]))\n",
    "    # We evaluate the observation 1\n",
    "    dummy[0,0] = 1\n",
    "    \n",
    "    P=loadingsMatrix\n",
    "    T=scoresMatrix\n",
    "\n",
    "    # Computes oMEDA\n",
    "    #self._mspc.computeoMEDA(testcs, dummy, self._model.get_pca().getLoadings())\n",
    "    if dummy.shape[0] == 1:\n",
    "      dummy = dummy.T\n",
    "\n",
    "    # To normalice the dummy vector [-1, 1]\n",
    "    if dummy[dummy > 0].size != 0:\n",
    "      dummy[dummy > 0] = dummy[dummy > 0] / np.max(dummy[dummy > 0])\n",
    "\n",
    "\n",
    "    if dummy[dummy < 0].size != 0:\n",
    "      dummy[dummy < 0] = (dummy[dummy < 0] / np.min(dummy[dummy < 0]))*(-1)\n",
    "\n",
    "    xA = np.dot(np.dot(testcs,P),P.T);   \n",
    "    sumA = np.dot(xA.T,dummy);       \n",
    "    sumTotal = np.dot(testcs.T,dummy);        \n",
    "\n",
    "    oMEDA = ((2*sumTotal - sumA)*np.abs(sumA)) / np.sqrt(np.dot(dummy.T,dummy))\n",
    "\n",
    "    diagnosis_vec=oMEDA\n",
    "\n",
    "    return diagnosis_vec\n",
    "    \n",
    "diagnosis_vec=omeda(test,testcs,loadingsMatrix,scoresMatrix)\n",
    "diagnosis_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de preprocesado dinámico, tiene algunas diferencisa al respecto del preprocesado\n",
    "#inicial\n",
    "def preprocess2Di(x, prep, lamda, average, scale, N, weights):\n",
    "\n",
    "    method_name = \"preprocess_2D()\"\n",
    "\n",
    "    # EWMA mean update model\n",
    "    # M_t^x = lambda * M_(t-1)^x + X_t\n",
    "    # m_t^x = (1/N_t) * M_t^x\n",
    "    # N_t = lambda * N_(t-1) + B_t\n",
    "\n",
    "    # acc <=> M_t^x --> Current model accumulated\n",
    "    # average <=> m_t^x --> Current model mean\n",
    "    acc = average*N;\n",
    "\n",
    "    # acc2 <=> (sigma_t^x)^2 --> Current model variability accumulated\n",
    "    # scale <=> sigma_t^x --> Current model standard deviation\n",
    "    acc2 = (scale**2)*np.max([N-1,0]);\n",
    "\n",
    "    # Current number of real observations to compute the mean and standard\n",
    "    # deviation\n",
    "    N = lamda*N + x.shape[0];\n",
    "\n",
    "    try:\n",
    "\n",
    "        if prep == 1:# mean centering\n",
    "\n",
    "            #logging.debug(\"EWMA mean centering\")\n",
    "\n",
    "            # Computes the current model mean\n",
    "            acc = lamda*acc + np.sum(x, axis=0)\n",
    "            average = acc/N\n",
    "            average = average.reshape(1,x.shape[1])\n",
    "            # array 1xM, being M the number of variables.\n",
    "            scale = np.ones((1,x.shape[1]))\n",
    "            # subtract the average to the data set x\n",
    "            xcs = x - np.dot(np.ones((x.shape[0],1)),average)\n",
    "\n",
    "            # TODO: do test with NaN in the data set\n",
    "\n",
    "        elif prep == 2: # auto-scaling\n",
    "            #EWMA auto-scaling\n",
    "            \n",
    "\n",
    "            # Computes the current model mean\n",
    "            acc = lamda*acc + np.sum(x, axis=0)\n",
    "            average = acc/N;\n",
    "            average = average.reshape(1,x.shape[1])\n",
    "\n",
    "            # subtract the average to the data set x\n",
    "            xc = x - np.dot(np.ones((x.shape[0],1)),average)\n",
    "            # Computes the current model standard deviation\n",
    "            acc2 = lamda*acc2 + np.sum(xc**2,axis=0)\n",
    "            scale = np.sqrt(acc2/(N-1))\n",
    "\n",
    "            # scale is all of zeros?\n",
    "            if np.nonzero(scale)[0].shape[0] == 0:\n",
    "                mS = 2\n",
    "            else:\n",
    "                mS = np.min(scale[np.nonzero(scale)])\n",
    "\n",
    "            scale[np.nonzero(scale == 0)] = mS/2# use 1 by default may reduce detection of anomalous events\n",
    "            # apply the scale\n",
    "            scale = scale.reshape(1,x.shape[1])\n",
    "            xcs = xc / np.dot(np.ones((x.shape[0],1)),scale)\n",
    "            \n",
    "            \n",
    "\n",
    "            # TODO: do test with NaN in the data set\n",
    "\n",
    "        elif prep == 3:\n",
    "            #EWMA scaling\n",
    "\n",
    "            # Computes the current model mean\n",
    "            average = np.zeros((1,x.shape[1]))\n",
    "\n",
    "            # Computes the current model standard deviation\n",
    "            acc2 = lamda*acc2 + np.sum(x**2,axis=0)\n",
    "            scale = np.sqrt(acc2/(N-1))\n",
    "\n",
    "            # scale is all of zeros?\n",
    "            if np.nonzero(scale)[0].shape[0] == 0:\n",
    "                mS = 2\n",
    "            else:\n",
    "                mS = np.min(scale[np.nonzero(scale)])\n",
    "\n",
    "            scale[np.nonzero(scale == 0)] = mS/2# use 1 by default may reduce detection of anomalous events\n",
    "            # apply the scale\n",
    "            scale = scale.reshape(1,x.shape[1])\n",
    "            xcs = x / np.dot(np.ones((x.shape[0],1)),scale)\n",
    "\n",
    "            # TODO: do test with NaN in the data set\n",
    "\n",
    "        else:\n",
    "            #logging.warn(\"The selected preprocessing method is not valid\")\n",
    "            average = np.zeros((1,x.shape[1]))\n",
    "            scale = np.ones((1,x.shape[1]))\n",
    "            xcs = x\n",
    "\n",
    "    except Exception:\n",
    "        #logging.error(\"Error preprocessing the data: %s\",sys.exc_info()[1])\n",
    "        #raise MSNMError(None,sys.exc_info()[1],method_name)\n",
    "        print \"Salta la excepcion\"\n",
    "    \n",
    "    #print \"El valor de xcs es: \", xcs\n",
    "\n",
    "    return xcs, average, scale, N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataXX:  (112, 112)\n",
      "La dimensiones de t son : (300, 112)\n",
      "Las dimensiones de p son: (112, 112)\n",
      "Las dimensiones de scoresMatrix son: (300, 2)\n",
      "Las dimensiones de loadingsMatrix son: (112, 2)\n",
      "Las dimensiones de model son: (300, 112)\n",
      "Las dimensiones de residualsMatrix son: (300, 112)\n",
      "Las dimensiones de eigengvaluesMatrix son: (112,)\n",
      "El valor de UCLQ:  150.6476374718253\n",
      "El valor de UCLD:  9.416825881055232\n"
     ]
    }
   ],
   "source": [
    "#self._sensor.do_dynamic_calibration(phase=2,lv=3,lamda=lambda_param)\n",
    "#self._model.calibrate_dynamically(self._data, **kwargs)\n",
    "\n",
    "\n",
    "EWMA = []\n",
    "EWMA = np.ndarray(EWMA)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def calibrate_dynamically(data,prep,**kwargs):\n",
    "    \n",
    "    method_name = \"calibrate()\"\n",
    "    \n",
    "    #Globales\n",
    "    global N\n",
    "    global av\n",
    "    global sd\n",
    "    global weights\n",
    "    global dataXX\n",
    "    \n",
    "    global scoresMatrix\n",
    "    global loadingsMatrix\n",
    "    global model\n",
    "    global residualsMatrix\n",
    "    global eigengvaluesMatrix\n",
    "    \n",
    "    global phase #Para el cálculo de los \n",
    "    \n",
    "    global EWMA\n",
    "    \n",
    "    global UCLD\n",
    "    global UCLQ\n",
    "    \n",
    "    global flag\n",
    "    \n",
    "    # Check the data type as ndarray\n",
    "    if not isinstance(data, np.ndarray):\n",
    "        raise ModelError(self,\"Data is not an ndarray\", method_name)\n",
    "    # Data must be a [NxM] ndarray\n",
    "    if (data.shape[0] < 1) or (data.shape[1] < 1):\n",
    "        raise ModelError(self,\"Data does not has [NxM] dimensions\", method_name)\n",
    "                \n",
    "    # TODO: currently weights is not implemented in prepprocess2D        \n",
    "    weights = np.ones((data.shape[0],1))\n",
    "        \n",
    "    # Check optional parameters\n",
    "    if 'prep' in kwargs:\n",
    "        prep = kwargs['prep']            \n",
    "    if 'lv' in kwargs:\n",
    "        lv = kwargs['lv']\n",
    "    if 'phase' in kwargs:\n",
    "        phase = kwargs['phase']\n",
    "    if 'lamda' in kwargs:\n",
    "        lamda = kwargs['lamda']\n",
    "          \n",
    "\n",
    "        \n",
    "    # Removing NaN if they exist [NO IMPLEMENTADO EN EL EJEMPLO]\n",
    "    # TODO test this method\n",
    "    #data = tools.averagedMissingData(data, self._av)\n",
    "        \n",
    "    # Data preprocessing\n",
    "    dataxcs, av, sd, N = preprocess2Di(data, prep, lamda, av, sd, N, weights)\n",
    "        \n",
    "    # EWMA cross-product\n",
    "    dataXX = lamda * dataXX + np.dot(dataxcs.T, dataxcs)\n",
    "    dataXX.shape\n",
    "    if flag==0:\n",
    "        EWMA=dataXX\n",
    "        flag=1\n",
    "    else:\n",
    "        #EWMA=np.append(EWMA,dataXX)\n",
    "        #EWMA=np.concatenate((EWMA,dataXX))\n",
    "        pass\n",
    "\n",
    "    print \"dataXX: \", dataXX.shape\n",
    "    #print dataXX\n",
    "    \n",
    "         \n",
    "    # Compute PCA\n",
    "    #pca.setData(dataxcs)\n",
    "    #pca.setPCs(lv)\n",
    "    #pca.runPCA(method='eig', xxcrossdata=self._dataXX)\n",
    "    scoresMatrix,loadingsMatrix,model,residualsMatrix,eigengvaluesMatrix=pca(dataxcs, pcs,method=\"eig\",xxcrossdata=dataXX)\n",
    "             \n",
    "    # Compute UCLs\n",
    "    #self._mspc.computeUCLQ(self._pca.getResidual(), self._alpha)\n",
    "    nUCLQ=calcularUCLQ(res,p_value,N)\n",
    "    UCLQ=nUCLQ\n",
    "    #self._mspc.computeUCLD(self._lv, data.shape[0], self._alpha, self._phase)\n",
    "    nUCLD=calcularUCLD(nobs,p_value,nob,npc)   \n",
    "    UCLD=nUCLD\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "N=0\n",
    "av=average \n",
    "sd=scale\n",
    "weights = np.ones((data.shape[0],1))\n",
    "lambda_param= 0.1\n",
    "dataXX = np.zeros([])\n",
    "\n",
    "\n",
    "\n",
    "calibrate_dynamically(data,prep,phase=2,lv=3,lamda=lambda_param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo de calibración dinámica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generamos las condiciones para ver los efectos de la calibración dinámica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataXX:  (112, 112)\n",
      "La dimensiones de t son : (300, 112)\n",
      "Las dimensiones de p son: (112, 112)\n",
      "Las dimensiones de scoresMatrix son: (300, 2)\n",
      "Las dimensiones de loadingsMatrix son: (112, 2)\n",
      "Las dimensiones de model son: (300, 112)\n",
      "Las dimensiones de residualsMatrix son: (300, 112)\n",
      "Las dimensiones de eigengvaluesMatrix son: (112,)\n",
      "El valor de UCLQ:  135.53754344269075\n",
      "El valor de UCLD:  9.416825881055232\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06535611, 0.42951096, 0.63193162, ..., 0.33387394, 0.78604108,\n",
       "        0.12581832],\n",
       "       [0.2408129 , 0.28347313, 0.28069742, ..., 0.43963621, 0.66034527,\n",
       "        0.10979488],\n",
       "       [0.2326514 , 0.75033998, 0.6664829 , ..., 0.52665213, 0.8394929 ,\n",
       "        0.81952674],\n",
       "       ...,\n",
       "       [0.05032022, 0.59124943, 0.81220111, ..., 0.66536334, 0.98966741,\n",
       "        0.18489501],\n",
       "       [0.52149005, 0.13606064, 0.90644497, ..., 0.58895048, 0.28085749,\n",
       "        0.10084853],\n",
       "       [0.8394852 , 0.08112918, 0.35008081, ..., 0.98563117, 0.74958553,\n",
       "        0.65949125]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dynamic Calibration\n",
    "\n",
    "#Definimos el número observaciones que necesitamos almacenar para lanzar la calibración \n",
    "#dinámica\n",
    "batch=15\n",
    "\n",
    "flag_dynamicC=0\n",
    "\n",
    "data_calibration = []\n",
    "data_calibration = np.array(data_calibration)\n",
    "\n",
    "\n",
    "for i in range(batch):\n",
    "    test=np.random.random((1,nvar))\n",
    "    #test=np.ones((1,nvar))*100\n",
    "    \n",
    "    \n",
    "    test = test.reshape((1,test.size))\n",
    "\n",
    "    testMeanCenterting = test - np.dot(np.ones((test.shape[0],1)),average)\n",
    "    testAutoScaled = testMeanCenterting / (np.dot(np.ones((test.shape[0],1)),scale))\n",
    "    testcs = testAutoScaled\n",
    "    test = test.reshape((1,test.size))    \n",
    "\n",
    "    if flag_dynamicC==0:\n",
    "        data_calibration=test\n",
    "        flag_dynamicC=1\n",
    "    else:\n",
    "        data_calibration=np.concatenate((data_calibration,test))\n",
    "        #data_calibration=np.concatenate((calibration_matrix,test)) Esto es un desliz pero lo dejo comentado por si acaso\n",
    "\n",
    "\n",
    "#Ya tenemos en data_calibration batch observaciones, ahora llamamos a la calibracion \n",
    "#dinamica\n",
    "\n",
    "\n",
    "#data=np.array(data_calibration)\n",
    "#data.shape\n",
    "\n",
    "\n",
    "calibrate_dynamically(data,prep,phase=2,lv=3,lamda=lambda_param)\n",
    "    \n",
    "data_calibration.shape\n",
    "\n",
    "calibration_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POR AQUI, necesito concatenar bien las observaciones para que tenga 2 dimensiones \n",
    "y el shape correcto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[299.        , -23.93151787, -25.24761402, ...,  17.91777516,\n",
       "        -10.37360825,  -5.97982925],\n",
       "       [-23.93151787, 299.        ,  -6.88050703, ...,  12.18926371,\n",
       "        -11.09510737,  16.4815266 ],\n",
       "       [-25.24761402,  -6.88050703, 299.        , ...,  -8.05124712,\n",
       "        -15.4424891 , -10.01487303],\n",
       "       ...,\n",
       "       [ 17.91777516,  12.18926371,  -8.05124712, ..., 299.        ,\n",
       "         14.5223372 ,   5.28945343],\n",
       "       [-10.37360825, -11.09510737, -15.4424891 , ...,  14.5223372 ,\n",
       "        299.        ,  19.16513646],\n",
       "       [ -5.97982925,  16.4815266 , -10.01487303, ...,   5.28945343,\n",
       "         19.16513646, 299.        ]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#EWMA showing\n",
    "EWMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siguiente paso, representar los valores de EWMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aaa=np.random.random((5,4))\n",
    "LL=np.dot(aaa.T,aaa)\n",
    "LL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([27.57877464, 26.70509666, 26.3048182 , 25.94241623, 25.71694922,\n",
       "       25.22856218, 24.91255897, 24.63409323, 24.61269808, 24.36883185,\n",
       "       24.08443803, 23.82690388, 23.46366223, 23.29720512, 23.14082685,\n",
       "       22.85780389, 22.73209463, 22.41795621, 22.18577547, 22.09855268,\n",
       "       21.87179695, 21.78873382, 21.54470244, 21.46859059, 21.27734745,\n",
       "       21.13994236, 21.10014556, 20.82940602, 20.68076202, 20.40936619,\n",
       "       20.10795481, 20.0572798 , 19.89825486, 19.71552736, 19.54908151,\n",
       "       19.38865608, 19.18028839, 19.03442339, 18.98933466, 18.80535171,\n",
       "       18.71275374, 18.67576242, 18.37278256, 18.25871722, 18.08140678,\n",
       "       17.96797168, 17.7785607 , 17.52225408, 17.38856037, 17.16560901,\n",
       "       17.02233865, 16.84751273, 16.61290836, 16.53848422, 16.4133013 ,\n",
       "       16.24748657, 16.12547532, 15.96496015, 15.80829872, 15.61576019,\n",
       "       15.54434406, 15.39166307, 15.27964277, 15.24980914, 15.14212528,\n",
       "       14.84665135, 14.81677659, 14.65197588, 14.35265541, 14.21406056,\n",
       "       14.04002555, 13.93436307, 13.82345917, 13.69372527, 13.51889707,\n",
       "       13.31442935, 13.1718876 , 13.10476394, 12.98498113, 12.82530996,\n",
       "       12.73032003, 12.62200013, 12.46299091, 12.21711984, 12.00575451,\n",
       "       11.96410903, 11.82499454, 11.72209913, 11.40500905, 11.25762778,\n",
       "       11.19471073, 11.06433072, 10.88118933, 10.77260502, 10.59970704,\n",
       "       10.44102978, 10.22294388, 10.00311943,  9.92208329,  9.5393944 ,\n",
       "        9.43875579,  9.3605698 ,  9.17902804,  8.8787964 ,  8.4869435 ,\n",
       "        8.48425792,  8.27838423,  7.9807974 ,  7.73585998,  7.68273508,\n",
       "        7.30150136,  6.90633979])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r,t=linalg.eig(LL)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.23990765, -0.64942894,  0.02683989,  0.13227034],\n",
       "       [ 0.66215998,  0.08603792,  0.26567604, -0.23527503],\n",
       "       [ 1.05270911,  0.21521904, -0.14966422,  0.12564277],\n",
       "       [ 0.70539664,  0.39125935,  0.12288745,  0.35637467],\n",
       "       [ 1.26327438,  0.1944985 , -0.10950156, -0.31019713]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = np.dot(aaa,t)\n",
    "te\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52168465,  0.22134398, -0.82070098, -0.07281389],\n",
       "       [ 0.41665397,  0.76911836,  0.458306  ,  0.15751831],\n",
       "       [ 0.59903877, -0.39467129,  0.32883392, -0.61421118],\n",
       "       [ 0.44203749, -0.45132955,  0.09096021,  0.76982514]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
