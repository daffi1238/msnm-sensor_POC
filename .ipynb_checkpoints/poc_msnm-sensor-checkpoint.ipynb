{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple linear regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import time\n",
    "from scipy.stats import norm\n",
    "import numpy.linalg as linalg\n",
    "\n",
    "#Para el cálculo de UCL-D\n",
    "from scipy.stats import f as fisher\n",
    "from scipy.stats import beta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de la matriz de calibración son:  (500, 100)\n"
     ]
    }
   ],
   "source": [
    "#Generación e matriz aleatoria arbitraria\n",
    "nobs=500\n",
    "nvar=100\n",
    "calibration_matrix=np.random.random((nobs,nvar)) #matriz de 300x112\n",
    "#comprobar\n",
    "print \"Las dimensiones de la matriz de calibración son: \", calibration_matrix.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información adicional para el cálculo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuraciones\n",
    "tstsDateFormat='%Y%m%d%H%M'\n",
    "model_backup_path = \"data/calibration/\"\n",
    "datetime.strftime(datetime.now(),tstsDateFormat)\n",
    "\n",
    "#información del yaml de configuración principal\n",
    "prep=2\n",
    "lv=2\n",
    "phase=1\n",
    "x=calibration_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento de la matriz calibración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average:  [[0.48871138 0.50078807 0.50690502 0.51065344 0.50874669 0.48946152\n",
      "  0.50980088 0.49487546 0.5108441  0.50136045 0.50134169 0.49114484\n",
      "  0.52669783 0.51019645 0.49743698 0.50038884 0.49017541 0.48027746\n",
      "  0.49359491 0.49130226 0.49576418 0.49794623 0.51936947 0.50829503\n",
      "  0.5014895  0.50789613 0.49083259 0.49796943 0.49655537 0.48654021\n",
      "  0.50474761 0.49842377 0.4975223  0.49103405 0.49844119 0.48808331\n",
      "  0.49345789 0.51301596 0.51772255 0.50663727 0.50959861 0.49966073\n",
      "  0.49000907 0.5113159  0.50427663 0.49784232 0.50504336 0.50088141\n",
      "  0.49530099 0.49147545 0.51774671 0.50813994 0.50023683 0.50648372\n",
      "  0.50439069 0.52283546 0.49519418 0.49622091 0.48673449 0.50341496\n",
      "  0.52120517 0.4821559  0.51876391 0.49874233 0.48389197 0.52635353\n",
      "  0.50017004 0.5103706  0.49357218 0.51052526 0.48732748 0.51014808\n",
      "  0.50848585 0.50419509 0.48693157 0.52644287 0.49975255 0.51279725\n",
      "  0.50983951 0.50288908 0.47350716 0.48283662 0.49525695 0.50690938\n",
      "  0.51834134 0.50860574 0.49056575 0.5004615  0.49586915 0.52802289\n",
      "  0.48575749 0.48832171 0.48669143 0.50227469 0.51184657 0.51569643\n",
      "  0.53083017 0.51086855 0.49134951 0.49243807]]\n",
      "('Las dimensiones de average: ', (1, 100), ' Se busca el valor medio de csda')\n",
      "scale:  [[0.28081786 0.28535353 0.28303969 0.28815615 0.28653619 0.2848305\n",
      "  0.28228728 0.28031545 0.2855061  0.29218094 0.28607804 0.2920747\n",
      "  0.2885067  0.29024069 0.29489735 0.29587943 0.28874139 0.28718459\n",
      "  0.28590695 0.3002726  0.28097355 0.28811861 0.28855195 0.27860162\n",
      "  0.28891109 0.29536766 0.27950533 0.28435542 0.28485001 0.28847015\n",
      "  0.29334506 0.28603531 0.29102849 0.28054975 0.28594519 0.29104908\n",
      "  0.29315825 0.29382041 0.29383586 0.2874238  0.28103806 0.28290523\n",
      "  0.29655089 0.29566217 0.2868274  0.29836044 0.28688311 0.28984357\n",
      "  0.28098251 0.29213686 0.27548421 0.29188002 0.29316788 0.30161609\n",
      "  0.28269034 0.2934452  0.28815231 0.28301607 0.28596122 0.28923376\n",
      "  0.28652188 0.28691035 0.28174238 0.28502724 0.29380887 0.29226923\n",
      "  0.29137182 0.28855078 0.29446992 0.28726017 0.28756115 0.29944911\n",
      "  0.28692834 0.2915794  0.29187488 0.28495547 0.2831277  0.28826199\n",
      "  0.28275491 0.29161125 0.2910564  0.28161998 0.28461541 0.29567159\n",
      "  0.29360357 0.28985003 0.28676472 0.28660635 0.27809396 0.29242694\n",
      "  0.29041388 0.2909844  0.28831771 0.29821336 0.28803745 0.28275258\n",
      "  0.28467243 0.28930276 0.28737415 0.28265091]]\n",
      "Las dimensiones de scale son:  (1, 100) Se busca la desviación de cada columna para centrarla en 1\n",
      "xcs:  [[-0.38143336  1.28291139  0.65995088 ...  1.09528934  1.29002692\n",
      "  -0.89304971]\n",
      " [ 0.69106811 -1.03898474 -1.41742853 ... -1.50667974 -0.36335626\n",
      "  -1.32009043]\n",
      " [ 0.83566833 -0.51234486 -0.63974888 ...  1.46512015 -0.29127361\n",
      "   0.31420446]\n",
      " ...\n",
      " [-1.68085547 -1.52206255 -1.03144238 ...  1.52050329 -0.67164814\n",
      "   1.24045758]\n",
      " [ 1.5436353   1.46941921 -0.9481023  ...  0.10919143 -0.85675223\n",
      "   1.57675171]\n",
      " [-0.1290743  -1.09202619  0.38402362 ... -1.59941513  0.73329233\n",
      "   0.93700276]]\n",
      "Las dimensiones de xcs:  (500, 100)\n",
      "xcs es la matriz normalizada, con media 0 y desviación 1, paso necesario para aplicar PCA\n"
     ]
    }
   ],
   "source": [
    "#preprocesamiento -->method_name = \"preprocess_2D()\" La variables weight de momento en estos ejemplos no la tendremos en cuenta\n",
    "nanM = np.isnan(x)\n",
    "anM = 1 - nanM\n",
    "\n",
    "average = np.nanmean(x,axis=0)# array of M elements\n",
    "average = average.reshape((1,average.shape[0]))# Matrix of 1xM elements\n",
    "scale = np.nanstd(x,axis=0,ddof=1)\n",
    "\n",
    "#TODO: to ask Pepe what is this :(\n",
    "ind = np.nonzero(scale == 0)# # of zeroes in scale\n",
    "dem = 2.0*np.sum(anM[:,ind],axis=0) - 1\n",
    "scale[ind] = np.sqrt(np.ones((1,np.array(ind).size)) / dem)\n",
    "\n",
    "scale = scale.reshape((1,scale.shape[0]))# Matrix of 1xM elements\n",
    "xcs = x - np.dot(np.ones((x.shape[0],1)),average)\n",
    "xcs = xcs / np.dot(np.ones((x.shape[0],1)),scale)\n",
    "\n",
    "print \"average: \", average\n",
    "print (\"Las dimensiones de average: \", average.shape, \" Se busca el valor medio de csda\")#112x1, es decir, una media por cada columna\n",
    "\n",
    "print \"scale: \", scale\n",
    "print \"Las dimensiones de scale son: \", scale.shape, \"Se busca la desviación de cada columna para centrarla en 1\"\n",
    "\n",
    "#xcs tiene las dimensiones de la matriz original 300x112\n",
    "print \"xcs: \",xcs\n",
    "print \"Las dimensiones de xcs: \", xcs.shape\n",
    "print \"xcs es la matriz normalizada, con media 0 y desviación 1, paso necesario para aplicar PCA\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Las dimensiones de u: (500, 500)\n",
      "Las dimensiones de s: (500, 100)\n",
      "Las dimensiones de v: (100, 100)\n"
     ]
    }
   ],
   "source": [
    "#PCA; La llamada de la funcion def runPCA(self, method='svd', **kwargs):\n",
    "#El ejemplo lo describo con el método svd que es el usado por defecto\n",
    "# Run SVD from the data matrix\n",
    "data=xcs\n",
    "pcs=lv\n",
    "\n",
    "u, s, v = linalg.svd(data)\n",
    "\n",
    "# Transform S from array to matrix with the corresponding dimensions\n",
    "# in U and V\n",
    "#Este punto no he conseguido obtener una comprensión profunda mas alla de lo que menciona\n",
    "sdiag = np.diag(s)\n",
    "s = np.zeros((u.shape[1], v.shape[0]))\n",
    "s[:sdiag.shape[0], :sdiag.shape[1]] = sdiag\n",
    "\n",
    "print \"Las dimensiones de u: %s\" % str(u.shape)\n",
    "\n",
    "print \"Las dimensiones de s: %s\" % str(s.shape)\n",
    "\n",
    "print \"Las dimensiones de v: %s\" % str(v.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La dimensiones de t son : (500, 100)\n",
      "Las dimensiones de p son: (100, 100)\n",
      "Las dimensiones de scoresMatrix son: (500, 2)\n",
      "Las dimensiones de loadingsMatrix son: (100, 2)\n",
      "Las dimensiones de model son: (500, 100)\n",
      "Las dimensiones de residualsMatrix son: (500, 100)\n",
      "Las dimensiones de eigengvaluesMatrix son: (500, 100)\n"
     ]
    }
   ],
   "source": [
    "t = np.dot(u, s)   #  ->u: Matriz de similaridad de fila-clase       \n",
    "p = v.T         # ->v: Matriz de similaridad de columna-clase\n",
    "\n",
    "scoresMatrix = t[:, :pcs]  # (Las dos pc's)\n",
    "loadingsMatrix = p[:, :pcs] #M\n",
    "model = np.dot(scoresMatrix, loadingsMatrix.T) #Matriz de 300x112\n",
    "residualsMatrix = data - model #\n",
    "eigengvaluesMatrix = s #¿Qué uso tiene?\n",
    "\n",
    "print \"La dimensiones de t son : %s\" % str(t.shape)\n",
    "print \"Las dimensiones de p son: %s\" % str(p.shape)\n",
    "print \"Las dimensiones de scoresMatrix son: %s\" % str(scoresMatrix.shape)\n",
    "print \"Las dimensiones de loadingsMatrix son: %s\" % str(loadingsMatrix.shape)\n",
    "print \"Las dimensiones de model son: %s\" % str(model.shape)\n",
    "print \"Las dimensiones de residualsMatrix son: %s\" % str(residualsMatrix.shape)\n",
    "print \"Las dimensiones de eigengvaluesMatrix son: %s\" % str(eigengvaluesMatrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculamos los UCL's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definido en model.py\n",
    "alpha = 0.01\n",
    "\n",
    "\n",
    "####Para el calculo de UCLD\n",
    "phase=2\n",
    "mspc=lv\n",
    "npc=data.shape[0] #nº observaciones (300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCL-D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El valor de lim es: 9.143920634316563\n",
      "9.143920634316563\n"
     ]
    }
   ],
   "source": [
    "####Calculo de los UCL's\n",
    "#UCL-D\n",
    "#Definición\n",
    "#def computeUCLD(self,npc,nob,p_value,phase):\n",
    "#llamada\n",
    "#self._mspc.computeUCLD(self._lv, data.shape[0], self._alpha, self._phase)\n",
    "'''\n",
    "Parameters\n",
    "        ----------\n",
    "        npc: int \n",
    "            Number of PCs\n",
    "        nob: int \n",
    "            Number of observations\n",
    "        p_value: float \n",
    "            p-value of the test, in (0,1]\n",
    "        phase: int \n",
    "            SPC phase\n",
    "            1: Phase I\n",
    "            2: Phase II\n",
    "'''\n",
    "#method_name = \"computeUCLD()\"\n",
    "       \n",
    "#importar\n",
    "from scipy.stats import f as fisher\n",
    "\n",
    "####Para el calculo de UCLD\n",
    "phase=1\n",
    "npc=lv\n",
    "nob=data.shape[0]#nº observaciones (300)\n",
    "p_value=alpha #El p_value vale 0.01 muy significativo. A más pequeño más significativo. Basicamente busca le decimos a q que busque anomalías en el p-value dado\n",
    "\n",
    "        \n",
    "if phase == 2:\n",
    "   lim = (npc*(nob*nob-1.0)/(nob*(nob-npc)))*fisher.ppf(1-p_value,npc,nob-npc)\n",
    "else:\n",
    "   lim = (nob-1.0)**2/nob*beta.ppf(1-p_value,npc/2.0,(nob-npc-1)/2.0)\n",
    "         \n",
    "print \"El valor de lim es: %s\" %lim\n",
    "   \n",
    "# Check is the limit is and ndarray of [1x1] dimensions and get the float value\n",
    "if isinstance(lim, np.ndarray):\n",
    "   lim = lim[0,0]\n",
    "            \n",
    "# TODO: Sometimes after computations numpy takes UCLq as complex with 0j imaginary part\n",
    "if isinstance(lim, complex):\n",
    "   logging.warn(\"UCLd has a complex value of %s. Getting just the real part.\",lim)\n",
    "   lim = lim.real\n",
    "            \n",
    "UCLD=lim #Valor de ejemplo 9.416825881055232\n",
    "\n",
    "print UCLD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UCL-Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.965925860184758\n"
     ]
    }
   ],
   "source": [
    "#definido en model.py\n",
    "alpha = 0.01\n",
    "\n",
    "####Para el calculo de UCLQ\n",
    "res=residualsMatrix\n",
    "p_value=alpha #El p_value vale 0.01 muy significativo. A más pequeño más significativo. Basicamente busca le decimos a q que busque anomalías en el p-value dado\n",
    "# Rows of E matrix\n",
    "N = res.shape[0] #300 observaciones\n",
    "            \n",
    "# rank of E\n",
    "pcs_left = np.linalg.matrix_rank(res);#rango 110, este valor variará según la matriz utilizada\n",
    "    \n",
    "#\n",
    "lambda_eig = np.linalg.eigvals((1.0/(N-1))*np.dot(res.T,res)) #Array de 112 valores, \n",
    "# Get the DESC order according to the ABS value of eigenvalues\n",
    "lambda_eig = lambda_eig[np.abs(lambda_eig).argsort()[::-1]]        \n",
    "    \n",
    "theta1 = np.sum(lambda_eig[:pcs_left])\n",
    "theta2 = np.sum(lambda_eig[:pcs_left]**2)\n",
    "theta3 = np.sum(lambda_eig[:pcs_left]**3)\n",
    "    \n",
    "h0 = 1-((2*theta1*theta3)/(3*theta2**2))\n",
    "    \n",
    "z = norm.ppf(1-p_value)\n",
    "\n",
    "UCLq = theta1*((z*np.sqrt(2*theta2*(h0**2))/theta1) + 1 + (theta2*h0*(h0-1)/(theta1**2)))**(1/h0)\n",
    "#Comprobaciones para evitar errorewres\n",
    "# Check is the limit is and ndarray of [1x1] dimensions and get the float value\n",
    "if isinstance(UCLq, np.ndarray):\n",
    "   UCLq = UCLq[0,0]\n",
    "                \n",
    "# TODO: Sometimes after computations numpy takes UCLq as complex with 0j imaginary part\n",
    "if isinstance(UCLq, complex):\n",
    "    logging.warn(\"UCLq has a complex value of %s. Getting just the real part.\",UCLq)\n",
    "    UCLq = UCLq.real\n",
    "\n",
    "UCLQ=UCLq #valor de ejemplo 150.99231878043952\n",
    "\n",
    "print UCLQ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cálculo de los estadísticos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.51333785]]\n"
     ]
    }
   ],
   "source": [
    "#Comenzamos con el cálculo de Q-st\n",
    "#Primero obtenemos un arry de 1x112\n",
    "test=np.random.random((1,5))\n",
    "#La preprocesamos, es una funcion distinta a la usada en la matriz de calibración\n",
    "#Es decir media 0 y desviación 1 respecto la calibración\n",
    "testMeanCenterting = test - np.dot(np.ones((test.shape[0],1)),average)\n",
    "testAutoScaled = testMeanCenterting / (np.dot(np.ones((test.shape[0],1)),scale))\n",
    "testcs = testAutoScaled\n",
    "#Ahora comenzamos el cálculo del estadístico, ¿Qué necesitamos?\n",
    "#self._mspc.computeQst(testcs, self._model.get_pca().getLoadings())\n",
    "#La observación preporcesada y la matriz Loading del PCA\n",
    "\n",
    "#def computeQst(self,testcs,P):\n",
    "P=loadingsMatrix\n",
    "#new scores from testcs and the loadings (Q) of the calibration model\n",
    "t = np.dot(testcs,P)\n",
    "# Model residuals from the observations in testcs\n",
    "e = testcs - np.dot(t,np.transpose(P))\n",
    "# Computes Q-statistics from the observations in testcs\n",
    "Qst = np.sum(np.power(e,2),axis=1).reshape(testcs.shape[0],1);\n",
    "#->Qst = 89.84502164\n",
    "\n",
    "print Qst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D-st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.774880354372762\n"
     ]
    }
   ],
   "source": [
    "#Partiendo de las ejecuciones anteriores cn ya test definido e incluso\n",
    "\"\"\"\n",
    "Parameters\n",
    "        ----------        \n",
    "        testcs: numpy.ndarray\n",
    "            [NxM] preprocessed billinear data set with the observations to be monitored.\n",
    "        P: numpy.ndarray \n",
    "            [MxA] Matrix to perform the projection from the original to the latent subspace. \n",
    "            For PCA (testcs = T*P'), this is the matrix of loadings\n",
    "        T: numpy.ndarray \n",
    "            [MxA] Matrix to perform the projection from the original to the latent subspace. \n",
    "            For PCA (testcs = T*P'), this is the matrix of scores\n",
    "\"\"\"\n",
    "testcs=testcs\n",
    "P=loadingsMatrix\n",
    "T=scoresMatrix\n",
    "#new scores from testcs and the loadings (R) of the calibration model\n",
    "t = np.dot(testcs,P)        \n",
    "            \n",
    "#inverse of the model calibration scores (T)\n",
    "#Note: inv() method just allows at least 2D arrays \n",
    "t_cov = np.cov(T,rowvar=False)\n",
    "\n",
    "try:\n",
    "\tinvCT = np.linalg.inv(t_cov)\n",
    "except LinAlgError:\n",
    "\tinvCT = 1 / t_cov\n",
    "\n",
    "#         if all(t_cov.shape):# True the shape tuple is empty\n",
    "#             # When T has only one variable -> cov(T) computes the variance\n",
    "#             invCT = 1 / t_cov\n",
    "#         else:    \n",
    "#             invCT = np.linalg.inv(t_cov)\n",
    "\n",
    "dotAux = np.dot(t,invCT)\n",
    "\n",
    "# Computes D-statistics from the observations in testcs\n",
    "Dst = np.sum(np.multiply(dotAux,t),axis=1).reshape(testcs.shape[0],1);\n",
    "            \n",
    "# Check is the statistic is and ndarray of [1x1] dimensions and get the float value\n",
    "if isinstance(Dst, np.ndarray):\n",
    "\tDst = Dst[0,0]\n",
    "            \n",
    "# TODO: Sometimes after computations numpy takes UCLq as complex with 0j imaginary part\n",
    "if isinstance(Dst, complex):\n",
    "\tlogging.warn(\"Dst has a complex value of %s. Getting just the real part.\",self._Dst)\n",
    "\tDst = Dst.real\n",
    "    \n",
    "print Dst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este punto tenemos calculado los UCL's correspondientes a una calibración y los estadísticos correspondientes a una observación. Para comprobar si tenermos una anomalía tan sólo debemos ver si ambos estadísticos se encuentran por debajo de sus UCL's respectivos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diagnóstico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El punto ahora es poder obtener el origen de dicha anomalía para ello se aplica el método oMEDA calculando un vector de diagnóstico de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.31102915],\n",
       "       [ 0.76384637],\n",
       "       [ 0.81820243],\n",
       "       [ 0.31136717],\n",
       "       [-1.25496098]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up which observations are compared\n",
    "dummy = np.zeros((1,test.shape[0]))\n",
    "# We evaluate the observation 1\n",
    "dummy[0,0] = 1\n",
    "\n",
    "# Computes oMEDA\n",
    "#self._mspc.computeoMEDA(testcs, dummy, self._model.get_pca().getLoadings())\n",
    "if dummy.shape[0] == 1:\n",
    "  dummy = dummy.T\n",
    "                            \n",
    "# To normalice the dummy vector [-1, 1]\n",
    "if dummy[dummy > 0].size != 0:\n",
    "  dummy[dummy > 0] = dummy[dummy > 0] / np.max(dummy[dummy > 0])\n",
    "\n",
    "\n",
    "if dummy[dummy < 0].size != 0:\n",
    "  dummy[dummy < 0] = (dummy[dummy < 0] / np.min(dummy[dummy < 0]))*(-1)\n",
    "                  \n",
    "xA = np.dot(np.dot(testcs,P),P.T);   \n",
    "sumA = np.dot(xA.T,dummy);       \n",
    "sumTotal = np.dot(testcs.T,dummy);        \n",
    "            \n",
    "oMEDA = ((2*sumTotal - sumA)*np.abs(sumA)) / np.sqrt(np.dot(dummy.T,dummy))\n",
    "\n",
    "diagnosis_vec=oMEDA\n",
    "\n",
    "diagnosis_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py27",
   "language": "python",
   "name": "py27"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
